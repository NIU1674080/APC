{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import seaborn as sns\n",
    "import string\n",
    "import numpy as np\n",
    "import random\n",
    "from plotly import graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\Nicolás\\.cache\\kagglehub\\datasets\\yasserh\\twitter-tweets-sentiment-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "path = kagglehub.dataset_download(\"yasserh/twitter-tweets-sentiment-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.path.join(path, \"Tweets.csv\")\n",
    "\n",
    "original_df = pd.read_csv(file_path, encoding=\"latin1\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping columns**\n",
    "\n",
    "To predict the sentiment behind the tweet using BOW and Bayesian Probability, we will have to drop some columns:\n",
    "- `textID`: Unique identificator for each tweet, it doesn't add any info to the sentiment so we can drop the column\n",
    "\n",
    "- `selected_text`: Using this column would be a little bit of cheating as we are precisely trying to predict which words are the most related to each sentiment and selected_text is already giving us that info. Although we can use the column later on to compare the results of our prediction with the selected text in the dataset, we will drop if for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0                I`d have responded, if I were going   neutral\n",
       "1      Sooo SAD I will miss you here in San Diego!!!  negative\n",
       "2                          my boss is bullying me...  negative\n",
       "3                     what interview! leave me alone  negative\n",
       "4   Sons of ****, why couldn`t they put them on t...  negative"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = original_df.drop(['textID', 'selected_text'], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick look at our data**\n",
    "\n",
    "Let's take a little look into the way data is organized in our dataset, we will visualize better our data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_f1c2c_row0_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_f1c2c_row1_col1 {\n",
       "  background-color: #1f6eb3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_f1c2c_row2_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_f1c2c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f1c2c_level0_col0\" class=\"col_heading level0 col0\" >sentiment</th>\n",
       "      <th id=\"T_f1c2c_level0_col1\" class=\"col_heading level0 col1\" >text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f1c2c_level0_row0\" class=\"row_heading level0 row0\" >1</th>\n",
       "      <td id=\"T_f1c2c_row0_col0\" class=\"data row0 col0\" >neutral</td>\n",
       "      <td id=\"T_f1c2c_row0_col1\" class=\"data row0 col1\" >11117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1c2c_level0_row1\" class=\"row_heading level0 row1\" >2</th>\n",
       "      <td id=\"T_f1c2c_row1_col0\" class=\"data row1 col0\" >positive</td>\n",
       "      <td id=\"T_f1c2c_row1_col1\" class=\"data row1 col1\" >8582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f1c2c_level0_row2\" class=\"row_heading level0 row2\" >0</th>\n",
       "      <td id=\"T_f1c2c_row2_col0\" class=\"data row2 col0\" >negative</td>\n",
       "      <td id=\"T_f1c2c_row2_col1\" class=\"data row2 col1\" >7781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x14f3a55a850>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\n",
    "temp.style.background_gradient(cmap='Blues_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mapping labels**\n",
    "\n",
    "Original target labels are 4 for positive, 2 for neutral and 0 for negative, but i think it would be easier to interprate and more intuitive if i changed the labels to 2 for positive, 1 for neutral and 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0                I`d have responded, if I were going          1\n",
       "1      Sooo SAD I will miss you here in San Diego!!!          0\n",
       "2                          my boss is bullying me...          0\n",
       "3                     what interview! leave me alone          0\n",
       "4   Sons of ****, why couldn`t they put them on t...          0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mapping labels\n",
    "label_mapping = {'negative': 0, 'neutral': 1, 'positive':2}\n",
    "df['sentiment'] = df['sentiment'].map(label_mapping)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning data**\n",
    "\n",
    "Let's make sure that there aren't any empty cells on our dataset and that we can work with all the data properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 1 NaN's\n"
     ]
    }
   ],
   "source": [
    "# Let's see if there are any NaN's in our tweets and treat them in case there are\n",
    "print(\"There is a total of\", df[\"text\"].isna().sum(), \"NaN's\")\n",
    "df[\"text\"] = df[\"text\"].fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After cleaning the column there are 0 NaN's\n"
     ]
    }
   ],
   "source": [
    "print(\"After cleaning the column there are\", df[\"text\"].isna().sum(), \"NaN's\")\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    if not isinstance(tweet, str):  # Invalid values check\n",
    "        return \"\"\n",
    "    tweet = re.sub(r\"@\\w+\", \"\", tweet)  # Eliminate mentions\n",
    "    tweet = re.sub(r\"#\\w+\", \"\", tweet)  # Eliminate hashtags\n",
    "    tweet = re.sub(r\"http\\S+|www\\S+\", \"\", tweet)  # Eliminate URL's\n",
    "    tweet = emoji.demojize(tweet)  # Convert emoji to text\n",
    "    tweet = re.sub(r\"[^a-zA-Z\\s]\", \"\", tweet)  # Eliminate special characters\n",
    "    tweet = tweet.lower().strip()  # Eliminate uppercase and spaces\n",
    "    return tweet\n",
    "\n",
    "df['cleaned_text'] = df[\"text\"].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with empty text: 7\n",
      "After dropping the rows there are 0 with empty text\n"
     ]
    }
   ],
   "source": [
    "empty_count = df[df[\"cleaned_text\"] == \"\"].shape[0]\n",
    "print(f\"Number of rows with empty text: {empty_count}\")\n",
    "\n",
    "df = df[df[\"cleaned_text\"] != \"\"]\n",
    "empty_count = df[df[\"cleaned_text\"] == \"\"].shape[0]\n",
    "print(f\"After dropping the rows there are {empty_count} with empty text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>id have responded if i were going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>my boss is bullying me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>what interview leave me alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>sons of  why couldnt they put them on the rele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                       cleaned_text\n",
       "0          1                  id have responded if i were going\n",
       "1          0         sooo sad i will miss you here in san diego\n",
       "2          0                             my boss is bullying me\n",
       "3          0                      what interview leave me alone\n",
       "4          0  sons of  why couldnt they put them on the rele..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We don't need the column text anymore as cleaned_text has all the important and clean information from that column so we drop it\n",
    "df = df.drop('text', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data visualization**\n",
    "\n",
    "I will do a little visualization of the data but the \"big\" part will come afterwards, once i have done the predictions, to compare the results of my analysis with the column `selected_text` in the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "text": [
          "neutral",
          "positive",
          "negative"
         ],
         "title": {
          "position": "top center",
          "text": "Funnel-Chart of Sentiment Distribution"
         },
         "type": "funnelarea",
         "values": [
          11117,
          8582,
          7781
         ]
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Distribution of sentiments in the dataset\n",
    "fig = go.Figure(go.Funnelarea(\n",
    "    text =temp.sentiment,\n",
    "    values = temp.text,\n",
    "    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n",
    "    ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will divide our data into train and test and start training our model to be able to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.67      0.59      0.63      1538\n",
      "     Neutral       0.60      0.65      0.63      2237\n",
      "    Positive       0.70      0.70      0.70      1720\n",
      "\n",
      "    accuracy                           0.65      5495\n",
      "   macro avg       0.66      0.65      0.65      5495\n",
      "weighted avg       0.65      0.65      0.65      5495\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 910  531   97]\n",
      " [ 370 1462  405]\n",
      " [  85  439 1196]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"cleaned_text\"], df[\"sentiment\"], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=10000, stop_words=\"english\")\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_bow, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_bow)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Negative\", \"Neutral\", \"Positive\"]))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aaaaaa' 'aaaaaaaaaaa' 'aaaaaaaaaahhhhhhhh' ... 'zulu' 'zuluxhosa' 'zzzz']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-10.76774788 -10.76774788 -10.0746007  ... -10.76774788 -10.76774788\n",
      "  -10.0746007 ]\n",
      " [-10.27194284 -10.27194284 -10.96509002 ... -10.27194284 -10.27194284\n",
      "  -10.96509002]\n",
      " [-10.87066149 -10.87066149 -10.87066149 ... -10.17751431 -10.87066149\n",
      "  -10.17751431]]\n"
     ]
    }
   ],
   "source": [
    "log_probs = model.feature_log_prob_\n",
    "print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Palabras clave para la clase 'Negative':\n",
      "day, going, sorry, work, sad, miss, like, dont, just, im\n",
      "\n",
      "Palabras clave para la clase 'Neutral':\n",
      "today, lol, got, work, like, dont, going, day, just, im\n",
      "\n",
      "Palabras clave para la clase 'Positive':\n",
      "like, great, thanks, mothers, just, im, happy, love, good, day\n"
     ]
    }
   ],
   "source": [
    "n_keywords = 10\n",
    "\n",
    "for i, label in enumerate([\"Negative\", \"Neutral\", \"Positive\"]):\n",
    "    top_indices = np.argsort(log_probs[i])[-n_keywords:]\n",
    "    top_words = [vocabulary[j] for j in top_indices]\n",
    "    print(f\"\\nPalabras clave para la clase '{label}':\")\n",
    "    print(\", \".join(top_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freakin hawt guys at this restaurantwhere im eating dinner with my father\n"
     ]
    }
   ],
   "source": [
    "#Transformar un ejemplo específico al formato BoW\n",
    "n = random.randint(0,1000)\n",
    "example_tweet = X_test.iloc[n]\n",
    "print(example_tweet)\n",
    "\n",
    "example_bow = vectorizer.transform([example_tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabra: dinner, Contribuciones (Negative, Neutral, Positive): [-8.20279852 -7.27621056 -6.95863849]\n",
      "Palabra: eating, Contribuciones (Negative, Neutral, Positive): [-7.72322544 -7.15842753 -7.65178567]\n",
      "Palabra: father, Contribuciones (Negative, Neutral, Positive): [-9.15830996 -9.57879565 -9.07890203]\n",
      "Palabra: freakin, Contribuciones (Negative, Neutral, Positive): [-8.28284123 -9.3556521  -9.07890203]\n",
      "Palabra: guys, Contribuciones (Negative, Neutral, Positive): [-6.83592224 -6.83795563 -6.45182089]\n",
      "Palabra: hawt, Contribuciones (Negative, Neutral, Positive): [-10.76774788  -9.57879565 -10.17751431]\n",
      "Palabra: im, Contribuciones (Negative, Neutral, Positive): [-3.87612198 -4.22457066 -4.44903923]\n"
     ]
    }
   ],
   "source": [
    "tweet_indices = example_bow.indices\n",
    "tweet_words = [vocabulary[i] for i in tweet_indices]\n",
    "tweet_contributions = {word: log_probs[:, idx] for word, idx in zip(tweet_words, tweet_indices)}\n",
    "\n",
    "for word, contrib in tweet_contributions.items():\n",
    "    print(f\"Palabra: {word}, Contribuciones (Negative, Neutral, Positive): {contrib}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras clave seleccionadas para el tweet: ['im', 'guys', 'eating', 'dinner', 'freakin']\n"
     ]
    }
   ],
   "source": [
    "predicted_class = model.predict(example_bow)[0]\n",
    "keywords = sorted(tweet_contributions.items(), key=lambda x: x[1][predicted_class], reverse=True)\n",
    "\n",
    "print(f\"Palabras clave seleccionadas para el tweet: {[word for word, contrib in keywords[:5]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>predicted_selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id have responded if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>id going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sooo sad i will miss you here in san diego</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>sooo sad miss san diego</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>my boss is bullying me</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>boss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what interview leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>interview leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sons of  why couldnt they put them on the rele...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>sons releases bought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>some shameless plugging for the best rangers f...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>plugging best rangers forum earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>am feedings for the baby are fun when he is al...</td>\n",
       "      <td>fun</td>\n",
       "      <td>baby fun smiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>soooo high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>journey wow u just became cooler  hehe is that...</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>journey wow just hehe possible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>as much as i love to be hopeful i reckon the c...</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
       "      <td>love im gonna cake stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i really really like the song love story by ta...</td>\n",
       "      <td>like</td>\n",
       "      <td>really really like song love taylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>my sharpie is running dangerously low on ink</td>\n",
       "      <td>DANGERously</td>\n",
       "      <td>running low ink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i want to go to music tonight but i lost my voice</td>\n",
       "      <td>lost</td>\n",
       "      <td>want music tonight lost voice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test test from the lg env</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>test test lg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>uh oh i am sunburned</td>\n",
       "      <td>Uh oh, I am sunburned</td>\n",
       "      <td>uh oh sunburned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sok trying to plot alternatives as we speak sigh</td>\n",
       "      <td>*sigh*</td>\n",
       "      <td>trying plot speak sigh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ive been sick for the past few days  and thus ...</td>\n",
       "      <td>sick</td>\n",
       "      <td>ive days looks didnt look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>is back home now      gonna miss every one</td>\n",
       "      <td>onna</td>\n",
       "      <td>home gonna miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>hes just not that into you</td>\n",
       "      <td>Hes just not that into you</td>\n",
       "      <td>hes just</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         cleaned_text  \\\n",
       "0                   id have responded if i were going   \n",
       "1          sooo sad i will miss you here in san diego   \n",
       "2                              my boss is bullying me   \n",
       "3                       what interview leave me alone   \n",
       "4   sons of  why couldnt they put them on the rele...   \n",
       "5   some shameless plugging for the best rangers f...   \n",
       "6   am feedings for the baby are fun when he is al...   \n",
       "7                                          soooo high   \n",
       "8                                         both of you   \n",
       "9   journey wow u just became cooler  hehe is that...   \n",
       "10  as much as i love to be hopeful i reckon the c...   \n",
       "11  i really really like the song love story by ta...   \n",
       "12       my sharpie is running dangerously low on ink   \n",
       "13  i want to go to music tonight but i lost my voice   \n",
       "14                          test test from the lg env   \n",
       "15                               uh oh i am sunburned   \n",
       "16   sok trying to plot alternatives as we speak sigh   \n",
       "17  ive been sick for the past few days  and thus ...   \n",
       "18         is back home now      gonna miss every one   \n",
       "19                         hes just not that into you   \n",
       "\n",
       "                                        selected_text  \\\n",
       "0                 I`d have responded, if I were going   \n",
       "1                                            Sooo SAD   \n",
       "2                                         bullying me   \n",
       "3                                      leave me alone   \n",
       "4                                       Sons of ****,   \n",
       "5   http://www.dothebouncy.com/smf - some shameles...   \n",
       "6                                                 fun   \n",
       "7                                          Soooo high   \n",
       "8                                         Both of you   \n",
       "9                        Wow... u just became cooler.   \n",
       "10  as much as i love to be hopeful, i reckon the ...   \n",
       "11                                               like   \n",
       "12                                        DANGERously   \n",
       "13                                               lost   \n",
       "14                         test test from the LG enV2   \n",
       "15                              Uh oh, I am sunburned   \n",
       "16                                             *sigh*   \n",
       "17                                               sick   \n",
       "18                                               onna   \n",
       "19                         Hes just not that into you   \n",
       "\n",
       "                predicted_selected_text  \n",
       "0                              id going  \n",
       "1               sooo sad miss san diego  \n",
       "2                                  boss  \n",
       "3                       interview leave  \n",
       "4                  sons releases bought  \n",
       "5     plugging best rangers forum earth  \n",
       "6                       baby fun smiles  \n",
       "7                            soooo high  \n",
       "8                                        \n",
       "9        journey wow just hehe possible  \n",
       "10             love im gonna cake stuff  \n",
       "11  really really like song love taylor  \n",
       "12                      running low ink  \n",
       "13        want music tonight lost voice  \n",
       "14                         test test lg  \n",
       "15                      uh oh sunburned  \n",
       "16               trying plot speak sigh  \n",
       "17            ive days looks didnt look  \n",
       "18                      home gonna miss  \n",
       "19                             hes just  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_keywords(tweet, vectorizer, model, log_probs, top_n=5):\n",
    "    bow = vectorizer.transform([tweet])\n",
    "    tweet_indices = bow.indices\n",
    "    tweet_words = [vocabulary[i] for i in tweet_indices]\n",
    "    tweet_contributions = {word: log_probs[:, idx] for word, idx in zip(tweet_words, tweet_indices)}\n",
    "    predicted_class = model.predict(bow)[0]\n",
    "    sorted_keywords = sorted(tweet_contributions.items(), key=lambda x: x[1][predicted_class], reverse=True)\n",
    "    top_keywords = {word for word, contrib in sorted_keywords[:top_n]}\n",
    "    ordered_keywords = [word for word in tweet.split() if word in top_keywords]\n",
    "    return \" \".join(ordered_keywords)\n",
    "\n",
    "# We apply it to the original dataset and we compare it to the oirignal column\n",
    "original_df[\"cleaned_text\"] = df[\"cleaned_text\"]\n",
    "original_df[\"predicted_selected_text\"] = df[\"cleaned_text\"].apply(lambda tweet: extract_keywords(tweet, vectorizer, model, log_probs))\n",
    "comparison = original_df[[\"cleaned_text\", \"selected_text\", \"predicted_selected_text\"]].head(20)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
